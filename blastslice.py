import os  # os ëª¨ë“ˆ ì¶”ê°€
import requests
import xml.etree.ElementTree as ET
import cv2
import random
import numpy as np
from io import BytesIO


class BlastSlice:
    def __init__(self, image_base_url, annotation_url, window_size=256, training_range=(0, 159)):
        self.image_base_url = image_base_url  # GitHub Raw ì´ë¯¸ì§€ URL
        self.annotation_file = "all_annotations.xml"  # XML íŒŒì¼ëª… ê³ ì •
        self.window_size = window_size
        self.training_range = training_range

        # GitHubì—ì„œ XML íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        response = requests.get(annotation_url)
        if response.status_code == 200:
            with open(self.annotation_file, "w") as f:
                f.write(response.text)
            print("ğŸ“‚ all_annotations.xml ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        else:
            raise Exception("âŒ XML íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        self.annotations = self.parse_annotation()

    def parse_annotation(self):
        """ XML ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ì´ë¯¸ì§€ë³„ ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ë¥¼ ì €ì¥ """
        tree = ET.parse(self.annotation_file)
        root = tree.getroot()
        annotations = {}

        for image in root.findall('image'):
            image_name = image.get('name').strip().lower()
            boxes = []
            for box in image.findall('box'):
                xmin = float(box.get('xtl'))
                ymin = float(box.get('ytl'))
                xmax = float(box.get('xbr'))
                ymax = float(box.get('ybr'))
                if xmin >= 0 and ymin >= 0 and xmax > xmin and ymax > ymin:
                    boxes.append((xmin, ymin, xmax, ymax))
            annotations[image_name] = boxes
        return annotations

    def slice(self, window_size=None):
        """ GitHubì—ì„œ ì§ì ‘ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì™€ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìŠ¬ë¼ì´ì‹±í•˜ê³  ë°˜í™˜ """
        if window_size:
            self.window_size = window_size

        extracted_images = {}  # {íŒŒì¼ëª…: ì´ë¯¸ì§€ ë°°ì—´} í˜•íƒœë¡œ ë°˜í™˜
        extracted_annotations = {}  # {íŒŒì¼ëª…: ì–´ë…¸í…Œì´ì…˜ ë‚´ìš©} í˜•íƒœë¡œ ë°˜í™˜

        for image_name, boxes in self.annotations.items():
            image_number = int(image_name.split(".")[0])
            if image_number > self.training_range[1]:
                continue  # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ëŠ” ê±´ë„ˆëœ€

            # GitHub Raw URL ìƒì„±
            image_url = f"{self.image_base_url}/{image_name}"

            # GitHubì—ì„œ ì§ì ‘ ì´ë¯¸ì§€ ìš”ì²­
            response = requests.get(image_url)
            if response.status_code != 200:
                print(f"âŒ Error: {image_name} could not be loaded.")
                continue

            # OpenCVë¡œ ì´ë¯¸ì§€ ë””ì½”ë”©
            img_arr = np.asarray(bytearray(response.content), dtype=np.uint8)
            image = cv2.imdecode(img_arr, cv2.IMREAD_COLOR)
            if image is None:
                print(f"âŒ Error: Failed to decode {image_name}")
                continue

            img_height, img_width = image.shape[:2]
            image_counter = 1

            for (xmin, ymin, xmax, ymax) in boxes:
                box_width = xmax - xmin
                box_height = ymax - ymin

                if box_width > self.window_size or box_height > self.window_size:
                    print(f"Box too large for {image_name}, skipping.")
                    continue

                x_random_offset = random.randint(-int((self.window_size - box_width) / 2), int((self.window_size - box_width) / 2))
                y_random_offset = random.randint(-int((self.window_size - box_height) / 2), int((self.window_size - box_height) / 2))

                x_start = max(0, int(xmin) - x_random_offset)
                y_start = max(0, int(ymin) - y_random_offset)
                x_end = min(img_width, x_start + self.window_size)
                y_end = min(img_height, y_start + self.window_size)

                cropped_img = image[y_start:y_end, x_start:x_end]

                # ì´ë¯¸ì§€ê°€ window_sizeë³´ë‹¤ ì‘ìœ¼ë©´ ê²€ì€ìƒ‰ìœ¼ë¡œ ì±„ì›€
                top_padding = max(0, self.window_size - (y_end - y_start))
                left_padding = max(0, self.window_size - (x_end - x_start))

                cropped_img_padded = cv2.copyMakeBorder(
                    cropped_img,
                    top=top_padding,
                    bottom=0,
                    left=left_padding,
                    right=0,
                    borderType=cv2.BORDER_CONSTANT,
                    value=[0, 0, 0]
                )

                boxes_in_window = [
                    box for box in boxes if box[0] >= x_start and box[1] >= y_start and box[2] <= x_end and box[3] <= y_end
                ]
                if not boxes_in_window:
                    continue

                cropped_image_name = f"{os.path.splitext(image_name)[0]}-{image_counter}.jpg"
                annotation_data = []

                for box in boxes_in_window:
                    xmin, ymin, xmax, ymax = box
                    x_center = (xmin + xmax) / 2 - x_start + left_padding
                    y_center = (ymin + ymax) / 2 - y_start + top_padding
                    bbox_width = xmax - xmin
                    bbox_height = ymax - ymin
                    annotation_data.append(f"0 {x_center / self.window_size} {y_center / self.window_size} {bbox_width / self.window_size} {bbox_height / self.window_size}")

                # ì´ë¯¸ì§€ ì €ì¥ ì—†ì´ ë©”ëª¨ë¦¬ì— ì €ì¥ (BytesIO ì´ìš©)
                _, encoded_img = cv2.imencode(".jpg", cropped_img_padded)
                img_buffer = BytesIO(encoded_img.tobytes())

                extracted_images[cropped_image_name] = img_buffer
                extracted_annotations[cropped_image_name.replace(".jpg", ".txt")] = "\n".join(annotation_data)

                image_counter += 1

        return extracted_images, extracted_annotations
